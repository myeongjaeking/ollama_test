
"""
LangGraph + vLLM ë¡œì»¬ H100 ì—ì´ì „íŠ¸
http://192.168.0.84:8000 ì˜ vLLM ì„œë²„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, ToolMessage
from typing import Annotated, TypedDict, Sequence
import operator
import json

# ============================================================================
# API ì„¤ì •
# ============================================================================
base = "http://192.168.0.84:8000"
token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImM1NTlkOWM1LTk2OWQtNDk1MC05YTVhLWY3MGJlMTY1YTk1ZiIsImV4cCI6MTc3MTU3NTMzMywianRpIjoiMjgyYThkYWYtNzc4NS00MjliLWI1Y2ItMWIxYzFlNmMyZTA0MyJ9.VFDZueb-nRuU3ISLw4eDM6wKdOgGmaS1TjgExnErIY4"

headers = {
    "Authorization": token,
    "Content-Type": "application/json"
}

# ============================================================================
# 1. vLLM ë¡œì»¬ LLM ì„¤ì •
# ============================================================================
llm = ChatOpenAI(
    api_key=token,  # í† í° ê¸°ë°˜ ì¸ì¦
    model="openai/gpt-oss-120b",  # H100ì— ì˜¬ë ¤ì§„ ëª¨ë¸
    base_url=f"{base}/v1",  # /v1 ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
    temperature=0.7,
    top_p=0.9,
    max_tokens=1024,
)

# ============================================================================
# 2. State ì •ì˜
# ============================================================================
class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ì˜ ìƒíƒœ"""
    messages: Annotated[Sequence, operator.add]
    step_count: int


# ============================================================================
# 3. Tools ì •ì˜
# ============================================================================
@tool
def calculator(expression: str) -> str:
    """
    ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        expression: ê³„ì‚°í•  ìˆ˜ì‹ (ì˜ˆ: "100 + 250 * 2")
    
    Returns:
        ê³„ì‚° ê²°ê³¼
    """
    try:
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {expression} = {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"


@tool
def weather_check(city: str) -> str:
    """
    íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        city: ë„ì‹œ ì´ë¦„ (ì˜ˆ: "ì„œìš¸")
    
    Returns:
        ë‚ ì”¨ ì •ë³´
    """
    # ì‹¤ì œë¡œëŠ” APIë¥¼ í˜¸ì¶œí•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, ê¸°ì˜¨ 5Â°C, ìŠµë„ 45%",
        "ë¶€ì‚°": "íë¦¼, ê¸°ì˜¨ 8Â°C, ìŠµë„ 60%",
        "ëŒ€êµ¬": "ë§‘ìŒ, ê¸°ì˜¨ 6Â°C, ìŠµë„ 50%",
    }
    result = weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return result


@tool
def text_processor(text: str, operation: str) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        text: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
        operation: ì²˜ë¦¬ ë°©ì‹ ("uppercase", "lowercase", "reverse", "wordcount")
    
    Returns:
        ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if operation == "uppercase":
        return text.upper()
    elif operation == "lowercase":
        return text.lower()
    elif operation == "reverse":
        return text[::-1]
    elif operation == "wordcount":
        return f"ë‹¨ì–´ ê°œìˆ˜: {len(text.split())}"
    else:
        return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—…: {operation}"


@tool
def information_lookup(topic: str) -> str:
    """
    ì£¼ì œì— ëŒ€í•œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        topic: ì¡°íšŒí•  ì£¼ì œ
    
    Returns:
        ê´€ë ¨ ì •ë³´
    """
    information_db = {
        "íŒŒì´ì¬": "Pythonì€ 1991ë…„ Guido van Rossumì´ ê°œë°œí•œ ì¸í„°í”„ë¦¬í„° ì–¸ì–´ì…ë‹ˆë‹¤.",
        "AI": "AI(Artificial Intelligence)ëŠ” ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ, ê¸°ê³„ê°€ ì¸ê°„ì²˜ëŸ¼ í•™ìŠµí•˜ê³  íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "LangGraph": "LangGraphëŠ” LangChainì—ì„œ ì œê³µí•˜ëŠ” ìƒíƒœ ê·¸ë˜í”„ ê¸°ë°˜ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
    }
    return information_db.get(
        topic,
        f"{topic}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
    )


# ============================================================================
# 4. ì—ì´ì „íŠ¸ ë…¸ë“œ - LLMì´ tool í˜¸ì¶œ ì—¬ë¶€ë¥¼ ê²°ì •
# ============================================================================
def agent_node(state: AgentState):
    """
    LLMì„ ì‹¤í–‰í•˜ê³  tool í˜¸ì¶œ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    tools = [calculator, weather_check, text_processor, information_lookup]
    
    # Toolsë¥¼ LLMì— ë°”ì¸ë”©
    llm_with_tools = llm.bind_tools(tools)
    
    # LLM ì‹¤í–‰
    response = llm_with_tools.invoke(state["messages"])
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    return {
        "messages": [response],
        "step_count": state["step_count"] + 1
    }


# ============================================================================
# 5. Tool ì‹¤í–‰ ë…¸ë“œ
# ============================================================================
def tool_node(state: AgentState):
    """
    LLMì´ ìš”ì²­í•œ toolì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    last_message = state["messages"][-1]
    
    if not hasattr(last_message, "tool_calls") or not last_message.tool_calls:
        return {"messages": []}
    
    tool_results = []
    
    for tool_call in last_message.tool_calls:
        tool_name = tool_call["name"]
        tool_input = tool_call["input"]
        
        print(f"\nğŸ”§ Tool ì‹¤í–‰: {tool_name}")
        print(f"   ì…ë ¥: {tool_input}")
        
        # Tool ì‹¤í–‰
        if tool_name == "calculator":
            result = calculator.invoke(tool_input)
        elif tool_name == "weather_check":
            result = weather_check.invoke(tool_input)
        elif tool_name == "text_processor":
            result = text_processor.invoke(tool_input)
        elif tool_name == "information_lookup":
            result = information_lookup.invoke(tool_input)
        else:
            result = f"Unknown tool: {tool_name}"
        
        print(f"   ê²°ê³¼: {result}")
        
        # Tool ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
        tool_results.append(
            ToolMessage(
                content=result,
                tool_call_id=tool_call["id"],
                name=tool_name
            )
        )
    
    return {"messages": tool_results}


# ============================================================================
# 6. ì¡°ê±´ë¶€ ë¼ìš°íŒ… - tool í˜¸ì¶œ ì—¬ë¶€ íŒë‹¨
# ============================================================================
def should_continue(state: AgentState) -> str:
    """
    ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— tool_callsê°€ ìˆìœ¼ë©´ tool ì‹¤í–‰, ì—†ìœ¼ë©´ ì¢…ë£Œ
    """
    last_message = state["messages"][-1]
    
    # Tool callsê°€ ìˆìœ¼ë©´ tools ë…¸ë“œë¡œ, ì—†ìœ¼ë©´ ENDë¡œ
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    return "end"


# ============================================================================
# 7. ê·¸ë˜í”„ êµ¬ì„± ë° ì»´íŒŒì¼
# ============================================================================
def create_agent_graph():
    """
    LangGraph ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    graph_builder = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph_builder.add_node("agent", agent_node)
    graph_builder.add_node("tools", tool_node)
    
    # ì—£ì§€ ì¶”ê°€
    graph_builder.add_edge(START, "agent")  # ì‹œì‘ -> agent
    
    # ì¡°ê±´ë¶€ ì—£ì§€: agent -> (tools or end)
    graph_builder.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            "end": END,
        }
    )
    
    graph_builder.add_edge("tools", "agent")  # tools ì‹¤í–‰ í›„ ë‹¤ì‹œ agentë¡œ
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    return graph_builder.compile()


# ============================================================================
# 8. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================
def run_agent(user_query: str):
    """
    ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        user_query: ì‚¬ìš©ì ì¿¼ë¦¬
    """
    print("=" * 70)
    print("ğŸ¤– LangGraph + vLLM ì—ì´ì „íŠ¸ ì‹œì‘")
    print("=" * 70)
    print(f"ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: {user_query}\n")
    
    # ê·¸ë˜í”„ ìƒì„±
    agent_graph = create_agent_graph()
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "messages": [HumanMessage(content=user_query)],
        "step_count": 0
    }
    
    print("-" * 70)
    print("ğŸ“Š ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...\n")
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    try:
        final_state = agent_graph.invoke(initial_state)
        
        print("\n" + "-" * 70)
        print("âœ… ì—ì´ì „íŠ¸ ì™„ë£Œ\n")
        
        # ìµœì¢… ì‘ë‹µ ì¶œë ¥
        last_message = final_state["messages"][-1]
        
        print("=" * 70)
        print("ğŸ¯ ìµœì¢… ë‹µë³€:")
        print("=" * 70)
        if hasattr(last_message, "content"):
            print(last_message.content)
        else:
            print(str(last_message))
        
        print("\n" + "=" * 70)
        print(f"ì´ ë‹¨ê³„: {final_state['step_count']}")
        print("=" * 70)
        
        return final_state
        
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        print(f"   vLLM ì„œë²„ ì£¼ì†Œ: {base}")
        print(f"   API ì—”ë“œí¬ì¸íŠ¸: {base}/v1/chat/completions")
        print(f"\n   ë””ë²„ê¹… íŒ:")
        print(f"   1. ì„œë²„ ìƒíƒœ í™•ì¸: curl -H 'Authorization: {token[:20]}...' {base}/v1/models")
        print(f"   2. í† í° ìœ íš¨ì„± í™•ì¸")
        print(f"   3. ëª¨ë¸ëª… í™•ì¸: {llm.model}")
        return None


# ============================================================================
# 9. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
# ============================================================================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        
        "ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?",
        "LangGraphì— ëŒ€í•´ ì•Œë ¤ì¤˜",
        '"ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤"ë¥¼ ëŒ€ë¬¸ìë¡œ ë³€í™˜í•´ì¤„ ìˆ˜ ìˆì–´?',
    ]
    
    # ì²« ë²ˆì§¸ ì¿¼ë¦¬ ì‹¤í–‰
    run_agent(test_queries[0])